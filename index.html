<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>ZipLoRA</title>
<link href="./ZipLoRA_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./ZipLoRA_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./ZipLoRA_files/jquery.js"></script>
</head>
<body>
<div class="content">
  <h1><strong>ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs</strong></h1>
  <p id="authors"><a href="https://virajshah.com/">Viraj Shah<sup>1,2</sup></a><a href="https://natanielruiz.github.io/">Nataniel Ruiz<sup>1</sup></a> <a href="">Forrester Cole<sup>1</sup></a> <a href="">Erika Lu<sup>1</sup></a> <a href="https://slazebni.cs.illinois.edu/">Svetlana Lazebnik<sup>2</sup></a> <a href="http://people.csail.mit.edu/yzli/">Yuanzhen Li<sup>1</sup></a><a href="https://varunjampani.github.io/">Varun Jampani<sup>1</sup></a><br>
    <br>
  <span style="font-size: 24px; padding-right: 20px;"><sup>1</sup>Google Research</span><span style="font-size: 24px;padding-left: 20px;"><sup>2</sup>UIUC</span></p>
  <br>
  <img src="./ZipLoRA_files/teaser.jpg" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center"><em>Generate any subject in any style!</em></h3>
    <font size="+2">
          <p style="text-align: center;">
            <a href="" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="ZipLoRA_files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
    </font>
</div>
<!-- <div class="content">
  <h2 style="text-align:center;">Abstract</h2 >
  <p>Methods for finetuning generative models for concept-driven personalization generally achieve strong results for subject-driven or style-driven generation. Recently, low-rank adaptations (LoRA) have been proposed as a parameter-efficient way of achieving concept-driven personalization. While recent work explores the combination of separate LoRAs to achieve joint generation of learned styles and subjects, existing techniques do not reliably address the problem, so that either subject fidelity or style fidelity are compromised. We propose ZipLoRA, a method to cheaply and effectively merge independently trained style and subject LoRAs in order to achieve generation of any user-provided subject in any user-provided style. Experiments on a wide range of subject and style combinations show that ZipLoRA can generate compelling results with meaningful improvements over baselines in subject and style fidelity while preserving the ability to recontextualize.</p>
</div>
<div class="content">
  <h2>Background</h2>
  <p> </p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/background.png" style="width:100%;"> <br>
</div> -->
<div class="content">
  <h2>Approach</h2>
  <p>a simple yet effective method to generate any subject in any style by cheaply merging independently trained LoRAs for subject and style.</p>
  <hr style="height:20pt; visibility:hidden;" />
  <p>Our approach is based on three important observations:</p>
  <hr style="height:20pt; visibility:hidden;" />
  <p><strong>Observation 1:</strong> Unlike previous versions of Stable Diffusion, SDXL is able to learn styles using just a single exemplar image by following a DreamBooth protocol without any human feedback.</p>
  <img class="summary-img" src="./ZipLoRA_files/sdxl_style.jpg" style="width:70%;"> 
  <p><strong>Observation 2:</strong> LoRA weight matrix for all layers are sparse. Most of the elements in the LoRA weight matrix have very small magnitude, and have little effect on generation quality and fidelity.</p>
  <br>
  <p><strong>Observation 3:</strong>Columns of the weight matrices of two independently trained LoRAs may have varying levels of ``alignment'' between each other, as measured by cosine similarity, for example. We find that directly summing columns with high magnitude of cosine similarity degrades performance of the merged model.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/insights.jpg" style="width:100%;">
    <!-- <figcaption></figcaption> -->
  </figure>
  <br>
  <p>Based on these observations, we hypothesize that a method that operates akin to a zipper, aiming to reduce the quantity of similar-direction sums while preserving the content and style generation properties of the original LoRAs will yield more robust, higher-quality merges. Much like a zipper seamlessly joins two sides of a fabric, our proposed optimization-based approach finds a disjoint set of merger coefficients for blending the two LoRAs. This ensures that the merged LoRA adeptly captures both subject and style.</p>
  <img class="summary-img" src="./ZipLoRA_files/method_dia.jpg" style="width:100%;">
  <br>
</div>
<div class="content">
  <h2>Results</h2>
  <p></p>
<img class="summary-img" src="./ZipLoRA_files/results.png" style="width:100%;">
</div>
<div class="content">
  <h2>Art Rendition</h2>
  <p>Original artistic renditions of our subject dog in the style of famous painters. We remark that many of the generated poses were not seen in the training set, such as the Van Gogh and Warhol rendition. We also note that some renditions seem to have novel composition and faithfully imitate the style of the painter - even suggesting some sort of creativity (extrapolation given previous knowledge).</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/art.png" style="width:100%;"> <br>
</div>
<div class="content">
  <h2>Text-Guided View Synthesis</h2>
  <p>Our technique can synthesized images with specified viewpoints for a subject cat (left to right: top, bottom, side and back views). Note that the generated poses are  different from the input poses, and the background changes in a realistic manner given a pose change. We also highlight the preservation of complex fur patterns on the subject cat's forehead.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/novel_views.png" style="width:100%;"> <br>
</div>
<div class="content">
  <h2>Property Modification</h2>
  <p>We show color modifications in the first row (using prompts ``a [color] [V] car''), and crosses between a specific dog and different animals in the second row (using prompts ``a cross of a [V] dog and a [target species]''). We highlight the fact that our method preserves unique visual features that give the subject its identity or essence, while performing the required property modification.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/property_modification.png" style="width:100%;"> <br>
</div>
<div class="content">
  <h2>Accessorization</h2>
  <p>Outfitting a dog with accessories. The identity of the subject is preserved and many different outfits or accessories can be applied to the dog given a prompt of type <em>"a [V] dog wearing a police/chef/witch outfit''</em>. We observe a realistic interaction between the subject dog and the outfits or accessories, as well as a large variety of possible options.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/accessories.png" style="width:100%;"> <br>
</div>
<!-- <div class="content">
  <h2>Societal Impact</h2>
  <p>This project aims to provide users with an effective tool for synthesizing personal subjects (animals, objects) in different contexts. While general text-to-image models might be biased towards specific attributes when synthesizing images from text, our approach enables the user to get a better reconstruction of their desirable subjects. On contrary, malicious parties might try to use such images to mislead viewers. This is a common issue, existing in other generative models approaches or content manipulation techniques. Future research in generative modeling, and specifically of personalized generative priors, must continue investigating and revalidating these concerns.</p>
  <br>
</div>
<div class="content"> -->
  <h2>BibTex</h2>
  <code> @article{shah2023ZipLoRA,<br>
  &nbsp;&nbsp;title={ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs},<br>
  &nbsp;&nbsp;author={Shah, Viraj and Ruiz, Nataniel and Cole, Forrester and Lu, Erika and Lazebnik, Svetlana and Li, Yuanzhen and Jampani, Varun},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint arxiv},<br>
  &nbsp;&nbsp;year={2023}<br>
  } </code> 
</div>
<div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>:
    We thank Prafull Sharma, Meera Hahn, Jason Baldridge and Dilip Krishnan for helpful discussions and suggestions. We also thank Kihyuk Sohn for helping with the generation of StyleDrop results.
    <!-- Recycling a familiar <a href="https://chail.github.io/latent-composition/">template</a> ;). --> 
  </p>
</div>
</body>
</html>
