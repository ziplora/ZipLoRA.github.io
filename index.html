<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>ZipLoRA</title>
<link href="./ZipLoRA_files/style.css" rel="stylesheet">
<link rel="icon" type="image/x-icon" href="./favicon.ico">
<script type="text/javascript" src="./ZipLoRA_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./ZipLoRA_files/jquery.js"></script>
</head>
<body>
<div class="content">
  <h1><strong>ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs</strong></h1>
  <p id="authors"><a href="https://virajshah.com/">Viraj Shah<sup>1,2</sup></a><a href="https://natanielruiz.github.io/">Nataniel Ruiz<sup>1</sup></a> <a href="https://research.google/people/ForresterCole/">Forrester Cole<sup>1</sup></a> <a href="https://erikalu.com/">Erika Lu<sup>1</sup></a> <a href="https://slazebni.cs.illinois.edu/">Svetlana Lazebnik<sup>2</sup></a> <a href="http://people.csail.mit.edu/yzli/">Yuanzhen Li<sup>1</sup></a><a href="https://varunjampani.github.io/">Varun Jampani<sup>1</sup></a><br>
    <br>
  <span style="font-size: 24px; padding-right: 20px;"><sup>1</sup>Google Research</span><span style="font-size: 24px;padding-left: 20px;"><sup>2</sup>UIUC</span></p>
  <br>
  <img src="./ZipLoRA_files/teaser.jpg" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center"><em>Generate any subject in any style!</em></h3>
    <font size="+2">
          <p style="text-align: center;">
            <a href="https://arxiv.org/abs/2311.13600" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="ZipLoRA_files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
    </font>
</div>
<div class="content">
  <h2 style="text-align:center;">Abstract</h2 >
  <p>Methods for finetuning generative models for concept-driven personalization generally achieve strong results for subject-driven or style-driven generation. Recently, low-rank adaptations (LoRA) have been proposed as a parameter-efficient way of achieving concept-driven personalization. While recent work explores the combination of separate LoRAs to achieve joint generation of learned styles and subjects, existing techniques do not reliably address the problem, so that either subject fidelity or style fidelity are compromised. We propose ZipLoRA, a method to cheaply and effectively merge independently trained style and subject LoRAs in order to achieve generation of any user-provided subject in any user-provided style. Experiments on a wide range of subject and style combinations show that ZipLoRA can generate compelling results with meaningful improvements over baselines in subject and style fidelity while preserving the ability to recontextualize.</p>
</div>
<div class="content">
  <h2>Results: Personalized Stylization</h2>
  <p>ZipLoRA can generate stylizations of a specific object by combining various style and content LoRAs. Our method succeeds at both preserving the identity of the reference subject and capturing the unique characteristics of the reference style. We also provide comparisons with Direct Merge, Joint Training, and StyleDrop.</p>
<img class="summary-img" src="./ZipLoRA_files/compare_main.jpg" style="width:100%;">
</div>
<!-- <div class="content">
  <h2>Background</h2>
  <p> </p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/background.png" style="width:100%;"> <br>
</div> -->
<div class="content">
  <h2>Approach</h2>
  <p>A simple yet effective method to generate any subject in any style by cheaply merging independently trained LoRAs for subject and style.</p>
<!--  <hr style="height:5pt; visibility:hidden;" />-->
  <p>Our approach is based on three important observations:</p>
<!--  <hr style="height:20pt; visibility:hidden;" />-->
  <p><em>Observation 1:</em> Unlike previous versions of Stable Diffusion, SDXL is able to learn styles using just a single exemplar image by following a DreamBooth protocol without any human feedback.</p>
  <img class="summary-img" src="./ZipLoRA_files/sdxl_style.jpg" style="width:70%;"> 
  <p><em>Observation 2:</em> LoRA weight matrix for all layers are sparse. Most of the elements in the LoRA weight matrix have very small magnitude, and have little effect on generation quality and fidelity.</p>
  <p><em>Observation 3:</em> Columns of the weight matrices of two independently trained LoRAs may have varying levels of ``alignment'' between each other, as measured by cosine similarity, for example. We find that directly summing columns with high magnitude of cosine similarity degrades performance of the merged model.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/insights.jpg" style="width:100%;">
    <!-- <figcaption></figcaption> -->
  </figure>
  <br>
  <p>Based on these observations, we hypothesize that a method that operates akin to a zipper, aiming to reduce the quantity of similar-direction sums while preserving the content and style generation properties of the original LoRAs will yield more robust, higher-quality merges. Much like a zipper seamlessly joins two sides of a fabric, our proposed optimization-based approach finds a disjoint set of merger coefficients for blending the two LoRAs. This ensures that the merged LoRA adeptly captures both subject and style.</p>
  <img class="summary-img" src="./ZipLoRA_files/method_dia.jpg" style="width:100%;">
  <br>
</div>
<div class="content">
  <h2>Recontextualization</h2>
  <p>The merged ZipLoRA model can recontextualize reference objects in diverse contexts and with semantic modifications while maintaining stylization quality.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/recontext3.jpg" style="width:100%;"> <br>
</div>
<div class="content">
  <h2>Controlling the extent of stylization.</h2>
  <p>While it is not required, we can still tune the strength of object and style for added controllability.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/control.jpg" style="width:60%;"> <br>
</div>
<div class="content">
  <h2>Ability to produce the reference object and the style</h2>
  <p>Our approach retains the original behavior of both the models and can accurately generate specific structural and stylistic elements of each constituent LoRA, while direct merge fails.</p>
  <br>
  <img class="summary-img" src="./ZipLoRA_files/moe.jpg" style="width:70%;"> <br>
</div>
<!--<div class="content">-->
<!--  <h2>Accessorization</h2>-->
<!--  <p>Outfitting a dog with accessories. The identity of the subject is preserved and many different outfits or accessories can be applied to the dog given a prompt of type <em>"a [V] dog wearing a police/chef/witch outfit''</em>. We observe a realistic interaction between the subject dog and the outfits or accessories, as well as a large variety of possible options.</p>-->
<!--  <br>-->
<!--  <img class="summary-img" src="./ZipLoRA_files/accessories.png" style="width:100%;"> <br>-->
<!--</div>-->
<!-- <div class="content">
  <h2>Societal Impact</h2>
  <p>This project aims to provide users with an effective tool for synthesizing personal subjects (animals, objects) in different contexts. While general text-to-image models might be biased towards specific attributes when synthesizing images from text, our approach enables the user to get a better reconstruction of their desirable subjects. On contrary, malicious parties might try to use such images to mislead viewers. This is a common issue, existing in other generative models approaches or content manipulation techniques. Future research in generative modeling, and specifically of personalized generative priors, must continue investigating and revalidating these concerns.</p>
  <br>
</div> -->
<div class="content">
  <h2>BibTex</h2>
  <code> @article{shah2023ZipLoRA,<br>
  &nbsp;&nbsp;title={ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs},<br>
  &nbsp;&nbsp;author={Shah, Viraj and Ruiz, Nataniel and Cole, Forrester and Lu, Erika and Lazebnik, Svetlana and Li, Yuanzhen and Jampani, Varun},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint arxiv:2311.13600},<br>
  &nbsp;&nbsp;year={2023}<br>
  } </code> 
</div>
<div class="content" id="acknowledgements">
  <p><em>Acknowledgements</em>:
    We thank Prafull Sharma, Meera Hahn, Jason Baldridge and Dilip Krishnan for helpful discussions and suggestions. We also thank Kihyuk Sohn for helping with the generation of StyleDrop results.
  </p>
</div>
</body>
</html>
